{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\khush\\\\OneDrive\\\\Desktop\\\\frontend1\\\\src\\\\Chatbot.js\",\n  _s = $RefreshSig$();\nimport React, { useState, useRef } from \"react\";\nimport Recorder from \"recorder-js\";\nimport \"./Chatbot.css\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst backendUrl = \"\";\nconst MedicalChatbot = () => {\n  _s();\n  const [conversation, setConversation] = useState([]);\n  const [diagnosis, setDiagnosis] = useState(null);\n  const [error, setError] = useState(null);\n  const [isRecording, setIsRecording] = useState(false);\n  const [isProcessing, setIsProcessing] = useState(false);\n  const audioContextRef = useRef(null);\n  const recorderRef = useRef(null);\n  const silenceTimer = useRef(null);\n  const speechRef = useRef(null);\n  const handleStartRecording = async () => {\n    setError(null);\n    setIsRecording(true);\n    try {\n      audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();\n      const stream = await navigator.mediaDevices.getUserMedia({\n        audio: true\n      });\n      recorderRef.current = new Recorder(audioContextRef.current);\n      recorderRef.current.init(stream);\n      recorderRef.current.start();\n\n      // Set up silence detection\n      const audioInput = audioContextRef.current.createMediaStreamSource(stream);\n      const analyser = audioContextRef.current.createAnalyser();\n      audioInput.connect(analyser);\n      const checkSilence = () => {\n        const buffer = new Float32Array(analyser.fftSize);\n        analyser.getFloatTimeDomainData(buffer);\n        const maxAmplitude = Math.max(...buffer.map(Math.abs));\n        if (maxAmplitude < 0.01) {\n          // Silence threshold\n          if (!silenceTimer.current) {\n            silenceTimer.current = setTimeout(() => handleStopRecording(), 1500); // Stop after 1.5s of silence\n          }\n        } else {\n          clearTimeout(silenceTimer.current);\n          silenceTimer.current = null;\n        }\n        requestAnimationFrame(checkSilence);\n      };\n      checkSilence();\n    } catch (error) {\n      setError(\"Microphone access denied or not available.\");\n      setIsRecording(false);\n    }\n  };\n  const handleStopRecording = async () => {\n    setIsRecording(false);\n    setIsProcessing(true);\n    clearTimeout(silenceTimer.current);\n    try {\n      const {\n        blob\n      } = await recorderRef.current.stop();\n      const audioFile = new File([blob], \"audio.wav\", {\n        type: \"audio/wav\"\n      });\n      const formData = new FormData();\n      formData.append(\"file\", audioFile);\n\n      // Send recorded audio to backend\n      const transcriptionResponse = await fetch(`${backendUrl}/transcribe`, {\n        method: \"POST\",\n        body: formData\n      });\n      const transcriptionData = await transcriptionResponse.json();\n      if (transcriptionData.error) {\n        setError(transcriptionData.error);\n        setIsProcessing(false);\n        return;\n      }\n\n      // Update conversation with transcription\n      setConversation([{\n        role: \"AI\",\n        text: `Transcribed Text: ${transcriptionData.transcription}`\n      }]);\n\n      // Send text for analysis\n      const analysisResponse = await fetch(`${backendUrl}/analyze`, {\n        method: \"POST\",\n        headers: {\n          \"Content-Type\": \"application/json\"\n        },\n        body: JSON.stringify({\n          text: transcriptionData.transcription\n        })\n      });\n      const analysisData = await analysisResponse.json();\n      let formattedDiagnosis = analysisData.analysis.replace(\"**Key Symptoms Identified:**\", \"<strong><em>Key Symptoms Identified:</em></strong>\").replace(\"**Possible Medical Diagnosis:**\", \"<strong><em>Possible Medical Diagnosis:</em></strong>\").replace(\"**Follow-up Questions for Further Diagnosis:**\", \"<strong><em>Follow-up Questions for Further Diagnosis:</em></strong>\").replace(\"**Recommended Next Steps:**\", \"<strong><em>Recommended Next Steps:</em></strong>\");\n      setDiagnosis(formattedDiagnosis);\n    } catch (error) {\n      setError(\"Error processing the audio.\");\n    }\n    setIsProcessing(false);\n  };\n  const handlePlayDiagnosis = () => {\n    if (diagnosis) {\n      // Stop any ongoing speech\n      if (speechRef.current) {\n        window.speechSynthesis.cancel();\n      }\n      const speech = new SpeechSynthesisUtterance();\n      speech.text = diagnosis.replace(/<\\/?[^>]+(>|$)/g, \"\"); // Remove HTML tags for clean speech\n      speech.lang = \"en-US\"; // Set language to English\n      speech.rate = 1; // Adjust speed (1 is normal)\n      speech.pitch = 1; // Adjust pitch\n\n      speechRef.current = speech;\n      window.speechSynthesis.speak(speech);\n    }\n  };\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"chatbot-container\",\n    children: [/*#__PURE__*/_jsxDEV(\"h1\", {\n      children: \"Medical AI Chatbot\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 128,\n      columnNumber: 7\n    }, this), error && /*#__PURE__*/_jsxDEV(\"p\", {\n      className: \"error-message\",\n      children: [\"Error: \", error]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 129,\n      columnNumber: 17\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"chatbox\",\n      children: conversation.map((msg, index) => /*#__PURE__*/_jsxDEV(\"div\", {\n        className: \"message\",\n        children: [/*#__PURE__*/_jsxDEV(\"strong\", {\n          children: [msg.role, \": \"]\n        }, void 0, true, {\n          fileName: _jsxFileName,\n          lineNumber: 134,\n          columnNumber: 13\n        }, this), msg.text]\n      }, index, true, {\n        fileName: _jsxFileName,\n        lineNumber: 133,\n        columnNumber: 11\n      }, this))\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 131,\n      columnNumber: 7\n    }, this), diagnosis && /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"diagnosis-box\",\n      children: [/*#__PURE__*/_jsxDEV(\"h2\", {\n        children: \"Diagnosis\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 141,\n        columnNumber: 11\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        dangerouslySetInnerHTML: {\n          __html: diagnosis\n        }\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 142,\n        columnNumber: 11\n      }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n        onClick: handlePlayDiagnosis,\n        children: \"Play Diagnosis\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 143,\n        columnNumber: 11\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 140,\n      columnNumber: 9\n    }, this), !isRecording && !isProcessing && /*#__PURE__*/_jsxDEV(\"button\", {\n      onClick: handleStartRecording,\n      children: \"Start Recording\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 148,\n      columnNumber: 9\n    }, this), isRecording && /*#__PURE__*/_jsxDEV(\"p\", {\n      children: \"Listening... Speak now.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 151,\n      columnNumber: 23\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 127,\n    columnNumber: 5\n  }, this);\n};\n_s(MedicalChatbot, \"8ER57zNWMyhKxCrgqGwIo1uQras=\");\n_c = MedicalChatbot;\nexport default MedicalChatbot;\nvar _c;\n$RefreshReg$(_c, \"MedicalChatbot\");","map":{"version":3,"names":["React","useState","useRef","Recorder","jsxDEV","_jsxDEV","backendUrl","MedicalChatbot","_s","conversation","setConversation","diagnosis","setDiagnosis","error","setError","isRecording","setIsRecording","isProcessing","setIsProcessing","audioContextRef","recorderRef","silenceTimer","speechRef","handleStartRecording","current","window","AudioContext","webkitAudioContext","stream","navigator","mediaDevices","getUserMedia","audio","init","start","audioInput","createMediaStreamSource","analyser","createAnalyser","connect","checkSilence","buffer","Float32Array","fftSize","getFloatTimeDomainData","maxAmplitude","Math","max","map","abs","setTimeout","handleStopRecording","clearTimeout","requestAnimationFrame","blob","stop","audioFile","File","type","formData","FormData","append","transcriptionResponse","fetch","method","body","transcriptionData","json","role","text","transcription","analysisResponse","headers","JSON","stringify","analysisData","formattedDiagnosis","analysis","replace","handlePlayDiagnosis","speechSynthesis","cancel","speech","SpeechSynthesisUtterance","lang","rate","pitch","speak","className","children","fileName","_jsxFileName","lineNumber","columnNumber","msg","index","dangerouslySetInnerHTML","__html","onClick","_c","$RefreshReg$"],"sources":["C:/Users/khush/OneDrive/Desktop/frontend1/src/Chatbot.js"],"sourcesContent":["import React, { useState, useRef } from \"react\";\r\nimport Recorder from \"recorder-js\";\r\nimport \"./Chatbot.css\";\r\n\r\nconst backendUrl = \"\";\r\n\r\nconst MedicalChatbot = () => {\r\n  const [conversation, setConversation] = useState([]);\r\n  const [diagnosis, setDiagnosis] = useState(null);\r\n  const [error, setError] = useState(null);\r\n  const [isRecording, setIsRecording] = useState(false);\r\n  const [isProcessing, setIsProcessing] = useState(false);\r\n\r\n  const audioContextRef = useRef(null);\r\n  const recorderRef = useRef(null);\r\n  const silenceTimer = useRef(null);\r\n  const speechRef = useRef(null);\r\n\r\n  const handleStartRecording = async () => {\r\n    setError(null);\r\n    setIsRecording(true);\r\n\r\n    try {\r\n      audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();\r\n      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\r\n      recorderRef.current = new Recorder(audioContextRef.current);\r\n      recorderRef.current.init(stream);\r\n      recorderRef.current.start();\r\n\r\n      // Set up silence detection\r\n      const audioInput = audioContextRef.current.createMediaStreamSource(stream);\r\n      const analyser = audioContextRef.current.createAnalyser();\r\n      audioInput.connect(analyser);\r\n\r\n      const checkSilence = () => {\r\n        const buffer = new Float32Array(analyser.fftSize);\r\n        analyser.getFloatTimeDomainData(buffer);\r\n        const maxAmplitude = Math.max(...buffer.map(Math.abs));\r\n\r\n        if (maxAmplitude < 0.01) { // Silence threshold\r\n          if (!silenceTimer.current) {\r\n            silenceTimer.current = setTimeout(() => handleStopRecording(), 1500); // Stop after 1.5s of silence\r\n          }\r\n        } else {\r\n          clearTimeout(silenceTimer.current);\r\n          silenceTimer.current = null;\r\n        }\r\n        requestAnimationFrame(checkSilence);\r\n      };\r\n\r\n      checkSilence();\r\n    } catch (error) {\r\n      setError(\"Microphone access denied or not available.\");\r\n      setIsRecording(false);\r\n    }\r\n  };\r\n\r\n  const handleStopRecording = async () => {\r\n    setIsRecording(false);\r\n    setIsProcessing(true);\r\n    clearTimeout(silenceTimer.current);\r\n\r\n    try {\r\n      const { blob } = await recorderRef.current.stop();\r\n      const audioFile = new File([blob], \"audio.wav\", { type: \"audio/wav\" });\r\n\r\n      const formData = new FormData();\r\n      formData.append(\"file\", audioFile);\r\n\r\n      // Send recorded audio to backend\r\n      const transcriptionResponse = await fetch(`${backendUrl}/transcribe`, {\r\n        method: \"POST\",\r\n        body: formData,\r\n      });\r\n\r\n      const transcriptionData = await transcriptionResponse.json();\r\n      if (transcriptionData.error) {\r\n        setError(transcriptionData.error);\r\n        setIsProcessing(false);\r\n        return;\r\n      }\r\n\r\n      // Update conversation with transcription\r\n      setConversation([{ role: \"AI\", text: `Transcribed Text: ${transcriptionData.transcription}` }]);\r\n\r\n      // Send text for analysis\r\n      const analysisResponse = await fetch(`${backendUrl}/analyze`, {\r\n        method: \"POST\",\r\n        headers: { \"Content-Type\": \"application/json\" },\r\n        body: JSON.stringify({ text: transcriptionData.transcription }),\r\n      });\r\n\r\n      const analysisData = await analysisResponse.json();\r\n      let formattedDiagnosis = analysisData.analysis\r\n        .replace(\"**Key Symptoms Identified:**\", \"<strong><em>Key Symptoms Identified:</em></strong>\")\r\n        .replace(\"**Possible Medical Diagnosis:**\", \"<strong><em>Possible Medical Diagnosis:</em></strong>\")\r\n        .replace(\"**Follow-up Questions for Further Diagnosis:**\", \"<strong><em>Follow-up Questions for Further Diagnosis:</em></strong>\")\r\n        .replace(\"**Recommended Next Steps:**\", \"<strong><em>Recommended Next Steps:</em></strong>\");\r\n\r\n      setDiagnosis(formattedDiagnosis);\r\n    } catch (error) {\r\n      setError(\"Error processing the audio.\");\r\n    }\r\n\r\n    setIsProcessing(false);\r\n  };\r\n\r\n  const handlePlayDiagnosis = () => {\r\n    if (diagnosis) {\r\n      // Stop any ongoing speech\r\n      if (speechRef.current) {\r\n        window.speechSynthesis.cancel();\r\n      }\r\n\r\n      const speech = new SpeechSynthesisUtterance();\r\n      speech.text = diagnosis.replace(/<\\/?[^>]+(>|$)/g, \"\"); // Remove HTML tags for clean speech\r\n      speech.lang = \"en-US\"; // Set language to English\r\n      speech.rate = 1; // Adjust speed (1 is normal)\r\n      speech.pitch = 1; // Adjust pitch\r\n\r\n      speechRef.current = speech;\r\n      window.speechSynthesis.speak(speech);\r\n    }\r\n  };\r\n\r\n  return (\r\n    <div className=\"chatbot-container\">\r\n      <h1>Medical AI Chatbot</h1>\r\n      {error && <p className=\"error-message\">Error: {error}</p>}\r\n      \r\n      <div className=\"chatbox\">\r\n        {conversation.map((msg, index) => (\r\n          <div key={index} className=\"message\">\r\n            <strong>{msg.role}: </strong>{msg.text}\r\n          </div>\r\n        ))}\r\n      </div>\r\n\r\n      {diagnosis && (\r\n        <div className=\"diagnosis-box\">\r\n          <h2>Diagnosis</h2>\r\n          <p dangerouslySetInnerHTML={{ __html: diagnosis }}></p>\r\n          <button onClick={handlePlayDiagnosis}>Play Diagnosis</button>\r\n        </div>\r\n      )}\r\n\r\n      {!isRecording && !isProcessing && (\r\n        <button onClick={handleStartRecording}>Start Recording</button>\r\n      )}\r\n\r\n      {isRecording && <p>Listening... Speak now.</p>}\r\n    </div>\r\n  );\r\n};\r\n\r\nexport default MedicalChatbot;\r\n"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,QAAQ,EAAEC,MAAM,QAAQ,OAAO;AAC/C,OAAOC,QAAQ,MAAM,aAAa;AAClC,OAAO,eAAe;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAEvB,MAAMC,UAAU,GAAG,EAAE;AAErB,MAAMC,cAAc,GAAGA,CAAA,KAAM;EAAAC,EAAA;EAC3B,MAAM,CAACC,YAAY,EAAEC,eAAe,CAAC,GAAGT,QAAQ,CAAC,EAAE,CAAC;EACpD,MAAM,CAACU,SAAS,EAAEC,YAAY,CAAC,GAAGX,QAAQ,CAAC,IAAI,CAAC;EAChD,MAAM,CAACY,KAAK,EAAEC,QAAQ,CAAC,GAAGb,QAAQ,CAAC,IAAI,CAAC;EACxC,MAAM,CAACc,WAAW,EAAEC,cAAc,CAAC,GAAGf,QAAQ,CAAC,KAAK,CAAC;EACrD,MAAM,CAACgB,YAAY,EAAEC,eAAe,CAAC,GAAGjB,QAAQ,CAAC,KAAK,CAAC;EAEvD,MAAMkB,eAAe,GAAGjB,MAAM,CAAC,IAAI,CAAC;EACpC,MAAMkB,WAAW,GAAGlB,MAAM,CAAC,IAAI,CAAC;EAChC,MAAMmB,YAAY,GAAGnB,MAAM,CAAC,IAAI,CAAC;EACjC,MAAMoB,SAAS,GAAGpB,MAAM,CAAC,IAAI,CAAC;EAE9B,MAAMqB,oBAAoB,GAAG,MAAAA,CAAA,KAAY;IACvCT,QAAQ,CAAC,IAAI,CAAC;IACdE,cAAc,CAAC,IAAI,CAAC;IAEpB,IAAI;MACFG,eAAe,CAACK,OAAO,GAAG,KAAKC,MAAM,CAACC,YAAY,IAAID,MAAM,CAACE,kBAAkB,EAAE,CAAC;MAClF,MAAMC,MAAM,GAAG,MAAMC,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC;QAAEC,KAAK,EAAE;MAAK,CAAC,CAAC;MACzEZ,WAAW,CAACI,OAAO,GAAG,IAAIrB,QAAQ,CAACgB,eAAe,CAACK,OAAO,CAAC;MAC3DJ,WAAW,CAACI,OAAO,CAACS,IAAI,CAACL,MAAM,CAAC;MAChCR,WAAW,CAACI,OAAO,CAACU,KAAK,CAAC,CAAC;;MAE3B;MACA,MAAMC,UAAU,GAAGhB,eAAe,CAACK,OAAO,CAACY,uBAAuB,CAACR,MAAM,CAAC;MAC1E,MAAMS,QAAQ,GAAGlB,eAAe,CAACK,OAAO,CAACc,cAAc,CAAC,CAAC;MACzDH,UAAU,CAACI,OAAO,CAACF,QAAQ,CAAC;MAE5B,MAAMG,YAAY,GAAGA,CAAA,KAAM;QACzB,MAAMC,MAAM,GAAG,IAAIC,YAAY,CAACL,QAAQ,CAACM,OAAO,CAAC;QACjDN,QAAQ,CAACO,sBAAsB,CAACH,MAAM,CAAC;QACvC,MAAMI,YAAY,GAAGC,IAAI,CAACC,GAAG,CAAC,GAAGN,MAAM,CAACO,GAAG,CAACF,IAAI,CAACG,GAAG,CAAC,CAAC;QAEtD,IAAIJ,YAAY,GAAG,IAAI,EAAE;UAAE;UACzB,IAAI,CAACxB,YAAY,CAACG,OAAO,EAAE;YACzBH,YAAY,CAACG,OAAO,GAAG0B,UAAU,CAAC,MAAMC,mBAAmB,CAAC,CAAC,EAAE,IAAI,CAAC,CAAC,CAAC;UACxE;QACF,CAAC,MAAM;UACLC,YAAY,CAAC/B,YAAY,CAACG,OAAO,CAAC;UAClCH,YAAY,CAACG,OAAO,GAAG,IAAI;QAC7B;QACA6B,qBAAqB,CAACb,YAAY,CAAC;MACrC,CAAC;MAEDA,YAAY,CAAC,CAAC;IAChB,CAAC,CAAC,OAAO3B,KAAK,EAAE;MACdC,QAAQ,CAAC,4CAA4C,CAAC;MACtDE,cAAc,CAAC,KAAK,CAAC;IACvB;EACF,CAAC;EAED,MAAMmC,mBAAmB,GAAG,MAAAA,CAAA,KAAY;IACtCnC,cAAc,CAAC,KAAK,CAAC;IACrBE,eAAe,CAAC,IAAI,CAAC;IACrBkC,YAAY,CAAC/B,YAAY,CAACG,OAAO,CAAC;IAElC,IAAI;MACF,MAAM;QAAE8B;MAAK,CAAC,GAAG,MAAMlC,WAAW,CAACI,OAAO,CAAC+B,IAAI,CAAC,CAAC;MACjD,MAAMC,SAAS,GAAG,IAAIC,IAAI,CAAC,CAACH,IAAI,CAAC,EAAE,WAAW,EAAE;QAAEI,IAAI,EAAE;MAAY,CAAC,CAAC;MAEtE,MAAMC,QAAQ,GAAG,IAAIC,QAAQ,CAAC,CAAC;MAC/BD,QAAQ,CAACE,MAAM,CAAC,MAAM,EAAEL,SAAS,CAAC;;MAElC;MACA,MAAMM,qBAAqB,GAAG,MAAMC,KAAK,CAAC,GAAGzD,UAAU,aAAa,EAAE;QACpE0D,MAAM,EAAE,MAAM;QACdC,IAAI,EAAEN;MACR,CAAC,CAAC;MAEF,MAAMO,iBAAiB,GAAG,MAAMJ,qBAAqB,CAACK,IAAI,CAAC,CAAC;MAC5D,IAAID,iBAAiB,CAACrD,KAAK,EAAE;QAC3BC,QAAQ,CAACoD,iBAAiB,CAACrD,KAAK,CAAC;QACjCK,eAAe,CAAC,KAAK,CAAC;QACtB;MACF;;MAEA;MACAR,eAAe,CAAC,CAAC;QAAE0D,IAAI,EAAE,IAAI;QAAEC,IAAI,EAAE,qBAAqBH,iBAAiB,CAACI,aAAa;MAAG,CAAC,CAAC,CAAC;;MAE/F;MACA,MAAMC,gBAAgB,GAAG,MAAMR,KAAK,CAAC,GAAGzD,UAAU,UAAU,EAAE;QAC5D0D,MAAM,EAAE,MAAM;QACdQ,OAAO,EAAE;UAAE,cAAc,EAAE;QAAmB,CAAC;QAC/CP,IAAI,EAAEQ,IAAI,CAACC,SAAS,CAAC;UAAEL,IAAI,EAAEH,iBAAiB,CAACI;QAAc,CAAC;MAChE,CAAC,CAAC;MAEF,MAAMK,YAAY,GAAG,MAAMJ,gBAAgB,CAACJ,IAAI,CAAC,CAAC;MAClD,IAAIS,kBAAkB,GAAGD,YAAY,CAACE,QAAQ,CAC3CC,OAAO,CAAC,8BAA8B,EAAE,oDAAoD,CAAC,CAC7FA,OAAO,CAAC,iCAAiC,EAAE,uDAAuD,CAAC,CACnGA,OAAO,CAAC,gDAAgD,EAAE,sEAAsE,CAAC,CACjIA,OAAO,CAAC,6BAA6B,EAAE,mDAAmD,CAAC;MAE9FlE,YAAY,CAACgE,kBAAkB,CAAC;IAClC,CAAC,CAAC,OAAO/D,KAAK,EAAE;MACdC,QAAQ,CAAC,6BAA6B,CAAC;IACzC;IAEAI,eAAe,CAAC,KAAK,CAAC;EACxB,CAAC;EAED,MAAM6D,mBAAmB,GAAGA,CAAA,KAAM;IAChC,IAAIpE,SAAS,EAAE;MACb;MACA,IAAIW,SAAS,CAACE,OAAO,EAAE;QACrBC,MAAM,CAACuD,eAAe,CAACC,MAAM,CAAC,CAAC;MACjC;MAEA,MAAMC,MAAM,GAAG,IAAIC,wBAAwB,CAAC,CAAC;MAC7CD,MAAM,CAACb,IAAI,GAAG1D,SAAS,CAACmE,OAAO,CAAC,iBAAiB,EAAE,EAAE,CAAC,CAAC,CAAC;MACxDI,MAAM,CAACE,IAAI,GAAG,OAAO,CAAC,CAAC;MACvBF,MAAM,CAACG,IAAI,GAAG,CAAC,CAAC,CAAC;MACjBH,MAAM,CAACI,KAAK,GAAG,CAAC,CAAC,CAAC;;MAElBhE,SAAS,CAACE,OAAO,GAAG0D,MAAM;MAC1BzD,MAAM,CAACuD,eAAe,CAACO,KAAK,CAACL,MAAM,CAAC;IACtC;EACF,CAAC;EAED,oBACE7E,OAAA;IAAKmF,SAAS,EAAC,mBAAmB;IAAAC,QAAA,gBAChCpF,OAAA;MAAAoF,QAAA,EAAI;IAAkB;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAI,CAAC,EAC1BhF,KAAK,iBAAIR,OAAA;MAAGmF,SAAS,EAAC,eAAe;MAAAC,QAAA,GAAC,SAAO,EAAC5E,KAAK;IAAA;MAAA6E,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAI,CAAC,eAEzDxF,OAAA;MAAKmF,SAAS,EAAC,SAAS;MAAAC,QAAA,EACrBhF,YAAY,CAACuC,GAAG,CAAC,CAAC8C,GAAG,EAAEC,KAAK,kBAC3B1F,OAAA;QAAiBmF,SAAS,EAAC,SAAS;QAAAC,QAAA,gBAClCpF,OAAA;UAAAoF,QAAA,GAASK,GAAG,CAAC1B,IAAI,EAAC,IAAE;QAAA;UAAAsB,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAQ,CAAC,EAACC,GAAG,CAACzB,IAAI;MAAA,GAD9B0B,KAAK;QAAAL,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAEV,CACN;IAAC;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACC,CAAC,EAELlF,SAAS,iBACRN,OAAA;MAAKmF,SAAS,EAAC,eAAe;MAAAC,QAAA,gBAC5BpF,OAAA;QAAAoF,QAAA,EAAI;MAAS;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAI,CAAC,eAClBxF,OAAA;QAAG2F,uBAAuB,EAAE;UAAEC,MAAM,EAAEtF;QAAU;MAAE;QAAA+E,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAI,CAAC,eACvDxF,OAAA;QAAQ6F,OAAO,EAAEnB,mBAAoB;QAAAU,QAAA,EAAC;MAAc;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAQ,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAC1D,CACN,EAEA,CAAC9E,WAAW,IAAI,CAACE,YAAY,iBAC5BZ,OAAA;MAAQ6F,OAAO,EAAE3E,oBAAqB;MAAAkE,QAAA,EAAC;IAAe;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAQ,CAC/D,EAEA9E,WAAW,iBAAIV,OAAA;MAAAoF,QAAA,EAAG;IAAuB;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAG,CAAC;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OAC3C,CAAC;AAEV,CAAC;AAACrF,EAAA,CAnJID,cAAc;AAAA4F,EAAA,GAAd5F,cAAc;AAqJpB,eAAeA,cAAc;AAAC,IAAA4F,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}